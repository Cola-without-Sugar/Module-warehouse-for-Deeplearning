# 主干特征提取网路

这一部分主要对主干特征提取网络进行一个大方向的整理，我们要构造一个最基本的卷积神经网络需要对卷积层+激活函数+归一化组成的卷积块有一个了解。（关于分类改进的情况使用不同颜色的 **|** 进行标注，可以对相关改进部分进行索引）

## CNN（Convolutional Neural Networks）

### 卷积层

卷积层设计的主要特点有以下几种：

![卷积层](https://cdn.jsdelivr.net/gh/Cola-without-Sugar/markdown_img/202303221027665.png)   

**输入数据分割**	 主要包含对输入数据做分割的方式，如滑动窗口输入 <font color='A2CD5A'>**|**</font>

**卷积核设置** 		主要包括对卷积核权重的大小尺寸的调整 <font color='red'>**|**</font>

**输出数据拼接**	 对输出数据按照一定的规则进行拼接变换。<font color='cornflowerblue'>**|**</font>



#### 普通卷积

普通卷积层是实现卷积神经网络的基础，由卷积层的权重和输入输出组成。卷积运算实际上是对图像进行互相关运算，使用卷积核K对图像逐像素做运算。

使用了爱因斯坦简单式进行实现，同时使用unfold对输入进行快速滑动窗口分割，方便实现卷积。
![卷积层详解](https://cdn.jsdelivr.net/gh/Cola-without-Sugar/markdown_img/202303220943489.jpg)

#### 跨步卷积

跨步卷积主要改进的地方为，对滑动窗口的步幅进行调整，从原先的固定为1，转换为移动stride长度。

**跨步卷积去除了部分冗余且缩小了输出的尺寸，一定程度上取到了池化层的作用**

#### 空洞卷积 <font color='red'>**|**</font>

空洞卷积有一个参数可以设置dilation rate，具体含义就是在卷积核中相邻两个值内填充dilation rate-1个0。

![空洞卷积](https://cdn.jsdelivr.net/gh/Cola-without-Sugar/markdown_img/202303221313269.png)

上图为`dilation rate = 2 `的情况。

**空洞卷积的作用**

1. 扩大感受野

> 一般来说，在深度神经网络中增加感受野并且减少计算量的方法是下采样。但是下采样牺牲了空间分辨率和一些输入的信息。
>
> 空洞卷积一方面增大了感受野可以检测分割大目标，另一方面相较于下采样增大了分辨率可以精确定位目标。



1. 捕获多尺度上下文信息

> 当设置不同dilation rate时，感受野就会不一样，也即获取了多尺度信息



**空洞卷积的缺点**

1. 网格效应

> 仅仅多次叠加 dilation rate 相同的相同尺寸卷积核，会导致kernel 不连续，进而导致不是所有的像素都用来计算了，因此这会损失信息的连续性。
>
> ![网格效应](https://cdn.jsdelivr.net/gh/Cola-without-Sugar/markdown_img/202303221332650.png)

如图所示，白色网格相当于输入的图片，然后蓝色组成的那个框框就是卷积核，红色的点代表正在处理的像素点，可以看到红色点的旁边那一圈白色的像素点从头到尾都没有被利用到（都被乘0），所以红色那一点卷积后没有考虑到旁边这些白点的信息。



1. 远距离的信息可能不相关

> 如果光采用大的扩张率的卷积可能只对一些大物体分割有效果，那么对小目标来说就不太友好了。因此设计好空洞卷积层的关键在于如何同时处理不同大小物体的关系。

**空洞卷积的改进**

HDC:(混合空洞卷积)

> 1、叠加卷积的 dilation rate 不能有大于1的公约数，防止出现网格效应。比如[2，4，8]不行。
>
> 2、将扩张率设计成锯齿状结构，如[1,2,5,1,2,5]



#### 分组卷积

#### 深度卷积

#### 转置卷积

### 激活函数

### 归一化

## Transformer
