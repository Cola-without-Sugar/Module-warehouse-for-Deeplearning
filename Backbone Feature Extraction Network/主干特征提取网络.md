# 主干特征提取网路

这一部分主要对主干特征提取网络进行一个大方向的整理，我们要构造一个最基本的卷积神经网络需要对卷积层+激活函数+归一化组成的卷积块有一个了解。（关于分类改进的情况使用不同颜色的 **|** 进行标注，可以对相关改进部分进行索引）

## CNN（Convolutional Neural Networks）

### 卷积层

>主要参考博客[不同卷积讲解](https://blog.csdn.net/xhtchina/article/details/118698170)

> 推荐一篇详细讲解卷积的论文：A guide to convolution arithmetic for deep learning

卷积层设计的主要特点有以下几种：

![卷积层](https://cdn.jsdelivr.net/gh/Cola-without-Sugar/markdown_img/202303221027665.png)   

**输入数据分割**	 主要包含对输入数据做分割的方式，如滑动窗口输入 <font color='A2CD5A'>**|**</font>

**卷积核设置** 		主要包括对卷积核权重的大小尺寸和通道数的调整 <font color='red'>**|**</font>

**输出数据拼接**	 对输出数据按照一定的规则进行拼接变换。<font color='cornflowerblue'>**|**</font>





#### 原始卷积 (Vanilla Convolution)

普通卷积层是实现卷积神经网络的基础，由卷积层的权重和输入输出组成。卷积运算实际上是对图像进行互相关运算，使用卷积核K对图像逐像素做运算。

使用了爱因斯坦简单式进行实现，同时使用unfold对输入进行快速滑动窗口分割，方便实现卷积。
![卷积层详解](https://cdn.jsdelivr.net/gh/Cola-without-Sugar/markdown_img/202303220943489.jpg)

#### 跨步卷积 (Stride Convolution) <font color='A2CD5A'>**|**</font>

跨步卷积主要改进的地方为，对滑动窗口的步幅进行调整，从原先的固定为1，转换为移动stride长度。

**跨步卷积去除了部分冗余且缩小了输出的尺寸，一定程度上取到了池化层的作用**

#### 空洞卷积 (Atrous Convolution) <font color='red'>**|**</font> 

> 论文：Multi-Scale Context Aggregation by Dilated Convolutions[1]

空洞卷积有一个参数可以设置dilation rate，具体含义就是在卷积核中相邻两个值内填充dilation rate-1个0。

![空洞卷积](https://cdn.jsdelivr.net/gh/Cola-without-Sugar/markdown_img/202303221313269.png)

上图为`dilation rate = 2 `的情况。

**空洞卷积的作用**

1. 扩大感受野

> 一般来说，在深度神经网络中增加感受野并且减少计算量的方法是下采样。但是下采样牺牲了空间分辨率和一些输入的信息。
>
> 空洞卷积一方面增大了感受野可以检测分割大目标，另一方面相较于下采样增大了分辨率可以精确定位目标。



1. 捕获多尺度上下文信息

> 当设置不同dilation rate时，感受野就会不一样，也即获取了多尺度信息



**空洞卷积的缺点**

1. 网格效应

> 仅仅多次叠加 dilation rate 相同的相同尺寸卷积核，会导致kernel 不连续，进而导致不是所有的像素都用来计算了，因此这会损失信息的连续性。
>
> ![网格效应](https://cdn.jsdelivr.net/gh/Cola-without-Sugar/markdown_img/202303221332650.png)

如图所示，白色网格相当于输入的图片，然后蓝色组成的那个框框就是卷积核，红色的点代表正在处理的像素点，可以看到红色点的旁边那一圈白色的像素点从头到尾都没有被利用到（都被乘0），所以红色那一点卷积后没有考虑到旁边这些白点的信息。



1. 远距离的信息可能不相关

> 如果光采用大的扩张率的卷积可能只对一些大物体分割有效果，那么对小目标来说就不太友好了。因此设计好空洞卷积层的关键在于如何同时处理不同大小物体的关系。

**空洞卷积的改进**

HDC:(混合空洞卷积)

> 1、叠加卷积的 dilation rate 不能有大于1的公约数，防止出现网格效应。比如[2，4，8]不行。
>
> 2、将扩张率设计成锯齿状结构，如[1,2,5,1,2,5]



#### 分组卷积 (Group Convolution) <font color='red'>**|**</font>

> 论文：ImageNet Classification with Deep Convolutional Neural Networks[2]

分组卷积最早是在AlexNet[2]中提及,最早是作为工程实现被提及，下图展示了普通卷积和分组卷积的区别。

![分组卷积合](https://cdn.jsdelivr.net/gh/Cola-without-Sugar/markdown_img/202303231015225.png)

由图上可以知道，分组卷积的特点是通过分割卷积核组的通道数减少参数的计算量。在分组数为2的情况下由原来的$h\times w\times C\times C'$变为了$h\times w\times C/2\times C'/2\times 2$ 参数变为了一半。

**分组卷积的作用**

1. 减少了参数量并且便于并行运算

2. > 在某些情况下，分组卷积能带来的模型效果确实要优于标准的2D 卷积，是因为组卷积的方式能够增加相邻层filter之间的对角相关性，而且能够减少训练参数，不容易过拟合，这类似于正则的效果。

   <div align=center><img src="https://cdn.jsdelivr.net/gh/Cola-without-Sugar/markdown_img/202303231026849.png" alt="分组卷积的作用" style="zoom:200%;" /></div>

> 人们注意到过滤器组似乎始终将卷积层分成两个独立且不同的任务：黑白滤镜和彩色滤镜。
>
> [分组卷积的效果探讨](https://blog.yani.ai/filter-group-tutorial/) 通过查看相邻层卷积组的相关性表明卷积层组的作用是在**在通道维度上使用块对角线结构稀疏性进行学习**



**分组卷积存在的问题**

1. 实验表明分组卷积当分组数 = 2 时精度和参数量都有所提高。但是仍然存在一些问题尚未解决：

> 如何决定使用的卷积组的数量？卷积组之间可以重叠吗？是否所有组都必须具有相同的大小，异构卷积组又如何呢？

2. 数据信息只在本组里面存在，通道之间的信息没有流通，存在信息的屏蔽与阻塞，从而会丢失全局通道的信息。

**分组卷积的改进**

背景：原始的组卷积实现中，不同通道的特征会被划分到不同的组里面，直到网络的末端才将其融合起来，中间过程显然缺乏信息的交互（考虑到不同滤波器可提取到不同的特征）。

为了解决此问题。ShuffleNet结合逐点组卷积(Pointwise Convolution,PGC) 和 通道混洗 (channel shuffle)，来实现一个高效经量化的移动网络设计。提出了Shuffle单元。



#### 深度(可分离)卷积 (Depthwise Separable Convolution) <font color='red'>**|**</font> 

> 论文：《Xception: Deep Learning with Depthwise Separable Convolutions》[3] (Accepted by CVPR 2017)

深度可分离卷积，由深度卷积(Depthwise Convolution)和逐点卷积(Pointwise Convolution)两部分组成，后也被MobileNet等著名网络大规模应用。标准的卷积过程中对应图像区域中的所有通道均被同时考虑，而深度可分离卷积打破了这层瓶颈，将通道和空间区域分开考虑，对不同的输入通道采取不同的卷积核进行卷积，它将普通的卷积操作分解为两个过程，目的是希望能用较少的参数学习更丰富的特征表示。

![深度可分离卷积](https://cdn.jsdelivr.net/gh/Cola-without-Sugar/markdown_img/202303231243199.png)

深度可分离卷积的实现如下图所示，首先构建深度卷积 (Depthwise conv) 对输入的每个通道有一个负责的卷积核，因此，深度卷积的输出特征图数量等于输入特征图数量，无法进行有效的维度扩展。

由于一个特征图仅被一个滤波器卷积，无法有效的利用不同通道在相同空间位置上的特征信息，由此加入了逐点卷积 (Pointwise conv)。点卷积主要是要1×1卷积构成，负责将深度卷积的输出按通道投影到一个新的特征图上。

![深度可分离卷积1](https://cdn.jsdelivr.net/gh/Cola-without-Sugar/markdown_img/202303231244515.png)

**深度可分离卷积的优点：**

1. **降低参数量和计算量**  深度可分离卷积将原始的卷积运算分为两层，一层用于滤波（深度卷积），一层用于组合（逐点卷积）。这种分解过程能极大减少模型的参数量和计算量。

**深度可分离卷积的缺点：**

1. **降低模型容量** 深度可分离卷积在应用时并没有使用激活函数。此外，虽然深度可分离卷积可以显著的降低模型的计算量，但同时也会导致模型的容量显著降低，从而导致模型精度的下降。



#### 转置卷积

> 论文：[Fully Convolutional Networks for Semantic Segmentation](https://openaccess.thecvf.com/content_cvpr_2015/papers/Long_Fully_Convolutional_Networks_2015_CVPR_paper.pdf)[4]

转置卷积（transposed Convolutions）又名反卷积（deconvolution）或是分数步长卷积（fractially straced convolutions）。反卷积的概念第一次出现是Zeiler在2010年发表的论文Deconvolutional networks中。一般应用在编解码结构中的解码器部分或者DCGAN中的生成器中等。因为数字信号中有反卷积的概念而转置卷积通常只能恢复卷积的形状 (shape) 而不能恢复 值 (value) 。所以不能真正意义上称为反卷积。这一概念是在图像分割领域的里程碑之作 FCN 中得到关注。

![反卷积计算方式](https://cdn.jsdelivr.net/gh/Cola-without-Sugar/markdown_img/202303231349155.png)

转置卷积即是对卷积的运算过程进行逆运算，用于输出1对多的输出特征图。具体的公式的介绍可以看这个博文[转置卷积的推导](https://blog.csdn.net/qq_39478403/article/details/121181904)

**转置卷积的优点：**

1. **特征上采样** 利用转置卷积，可以引入参数让网络自动学习卷积核的权重以更好地恢复空间分辨率。一般来说，利用转置卷积来替代常规的上采样操作（最近邻插值、双线性插值即双立方插值）会取得更好的效果（在没有过拟合的情况下）
2. **特征可视化** 利用转置卷积还可以对特征图进行可视化。有时间的强烈推荐大家去阅读原论文《Visualizing and Understanding Convolutional Networks》，有助于帮助大家理解不同深度的各个特征图究竟学到了什么特征。比如，增加网络的深度有利于提取更加抽象的高级语义特征，而增加网络的宽度有利于增强特征多样性的表达。或者是小的卷积核有利于特征的学习，而小的步长则有利于保留更多的空间细节信息。



**转置卷积的缺点：**

1. **增加了参数量** 利用转置卷积进行学习上采样，增加了整个网络的学习权重的数量。
2.  **棋盘效应** 在进行上采样时，如果步长和卷积核尺寸选择不当，极易出现网格效应。具体可与参考[棋盘效应产生的原因及解决方案](https://zhuanlan.zhihu.com/p/548904297)



#### 1×1 卷积 

#### 可变形卷积

#### 空间可分离卷积

#### 图卷积

#### Inception 模块

#### 非对称卷积

#### Octave卷积

#### Het卷积

#### Cond卷积

#### 动态卷积

#### Ghost模块

#### 自校正卷积

#### Do-卷积

#### ResNeSt Block

#### 内卷(Involution)



### 激活函数





### 归一化

BN

GN



## Transformer





## 附录

### 1、参考文献

[1]Yu F , Koltun V . Multi-Scale Context Aggregation by Dilated Convolutions[C]// ICLR. 2016.

[2] Krizhevsky A ,  Sutskever I ,  Hinton G . ImageNet Classification with Deep Convolutional Neural Networks[J]. Advances in neural information processing systems, 2012, 25(2).

[3]Chollet F . Xception: Deep Learning with Depthwise Separable Convolutions[J]. IEEE, 2017.

[4] Long J , Shelhamer E , Darrell T . Fully Convolutional Networks for Semantic Segmentation[J]. IEEE Transactions on Pattern Analysis and Machine Intelligence, 2015, 39(4):640-651.
